---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# üòÉ About me
I am currently working as a postdoctoral researcher at KAIST as part of South Korea‚Äôs alternative 1-year military service (March 2025 ~ Feb 2026). My expertise lies in Generative AI technologies (e.g., diffusion models) across multiple modalities, including images, videos, and natural language. I obtained Ph.D. (2025) and M.S. (2021) at KAIST, advised by Professor [Chang D. Yoo](http://sanctusfactory.com/family.php).

<u>I will be available to start work in March 2026.</u>

I warmly welcome and appreciate any work opportunities given to me.

For more information, please refer to my [CV](https://drive.google.com/file/d/1kDQDw_m0SH67cUGQzCE2LJHY1CCOoS0q/view?usp=sharing).

# üìå Research Interests
- Computer Vision
- Generative AI
- Diffusion model
- Multi-modal Reasoning
- Causality and Debiasing
- Natural Language Processing



# üî• News
- *2025.06*: &nbsp;üéâ One paper accepted to ICCV 2025
- *2025.05*: &nbsp;üéâ One paper accepted to ICML 2025 (Spotlight)
- *2025.03*: &nbsp;üéâ Outstanding Ph.D. Dissertation Award, School of Electrical Engineering, KAIST, 2025
- *2025.02*: &nbsp;üéâ One paper accepted to CVPR 2025

# üè´ Education

- Mar.2021 - Feb.2025: __Ph.D.__ Electrical Engineering (KAIST)

&emsp;&emsp;&emsp;Thesis: "Diffusion-based Video Editing"

&emsp;&emsp;&emsp;Advisor: Prof. [Chang D. Yoo](http://sanctusfactory.com/family.php)

&emsp;&emsp;&emsp;<span style="color:#8B0000">Outstanding Ph.D. Dissertation Award, School of Electrical Engineering, KAIST, 2025 </span>

- Sep.2019 - Feb.2021: __M.S.__ Electrical Engineering (KAIST)

&emsp;&emsp;&emsp;Thesis: "Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval"

&emsp;&emsp;&emsp;Advisor: Prof. Chang D. Yoo

- Mar.2015 - Feb.2019: __B.S.__ Computer Science (DGIST)

&emsp;&emsp;&emsp;Advisor: Prof. Yongseob Lim

&emsp;&emsp;&emsp;<span style="color:#8B0000">Cum Laude </span>

# üìé Selected Publications 
[**10**] <span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Younghwan Lee, Ji Woo Hong and Chang D. Yoo, "Occlusion-robust Stylization for Drawing-based 3D Animation", International Conference on Computer Vision (**ICCV**) 2025

[**9**] <span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Younghwan Lee, and Chang D. Yoo, "TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation", Neural Information Processing Systems (**NeurIPS**) 2024

[**8**] <span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Ji Woo Hong, and Chang D. Yoo, "Dilutional Noise Initialization for Diffusion Video Editing", European Conference on Computer Vision (**ECCV**) 2024

[**7**] <span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Geonwoo Kim, and Chang D. Yoo, "FRAG: Frequency Adaptive Group for Diffusion Video Editing", International Conference on Machine Learning (**ICML**) 2024

[**6**] <span style="color:royalblue">**Sunjae Yoon** </span>, Dahyun Kim, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, and Chang D. Yoo, "HEAR: Hearing Enhanced Audio Response for Viode-grounded Dialogue", Findings of the Association for Computational Linguistics: **EMNLP** 2023 (long paper, findings)

[**5**] <span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Dahyun Kim, and Chang D. Yoo "SCANet: Scene Complexity Aware Network for Weakly-supervised Video Moment Retrieval", International Conference on Computer Vision (**ICCV**) 2023

[**4**] <span style="color:royalblue">**Sunjae Yoon** </span>, Ji Woo Hong, SooHwan Eom, Hee Suk Yoon, Eunseop Yoon, Daehyeok Kim, Junyeong Kim, Chanwoo Kim, and Chang D. Yoo, "Counterfactual Two-stage Debiasing Network for Video Corpus Moment Retrieval", The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2023, **Oral**

[**3**] <span style="color:royalblue">**Sunjae Yoon** </span>, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, and Chang D. Yoo "Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue", Conference on Empirical Methods in Natural Language Processing (**EMNLP**), 2022. (long paper)

[**2**] <span style="color:royalblue">**Sunjae Yoon** </span>, Ji Woo Hong, Eunseop Yoon, Dahyun Kim , Junyeong Kim, Hee Suk Yoon, and Chang D. Yoo, "Selective Query-guided Debiasing for Video Corpus Moment Retrieval", European Conference on Computer Vision (**ECCV**) 2022

[**1**] Minuk Ma *, <span style="color:royalblue">**Sunjae Yoon** </span> *, Junyeong Kim, Youngjuoon Lee, Sunghun Kang, and Chang D. Yoo, "VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval", European Conference on Computer Vision (**ECCV**) 2020 (equal contribution)

# üìù Publications (27 publications, 15 fisrt-author)

[*] equal contribution

## 2025
<div class='paper-box'><div class='paper-box-image'><div class="badge">ICCV 2025</div><img src='images/iccv2025.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C21**] **Occlusion-robust Stylization for Drawing-based 3D Animation**

<span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Younghwan Lee, Ji Woo Hong, and Chang D. Yoo

International Conference on Computer Vision (**ICCV**) 2025

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICML 2025</div><img src='images/icml2025.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C20**] **FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields**

Gwanhyeong Koo, <span style="color:royalblue">**Sunjae Yoon** </span>, Younghwan Lee, Ji Woo Hong, and Chang D. Yoo

International Conference on Machine Learning (**ICML**) 2025, <span style="color:#8B0000">**Spotlight**</span> (<2.6%)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">CVPR 2025</div><img src='images/cvpr2025.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C19**] **ITA-MDT:Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On**

Ji Woo Hong, Tri Ton, Trung X. Pham, Gwanhyeong Koo, <span style="color:royalblue">**Sunjae Yoon** </span>, Chang D. Yoo

Computer Vision and Pattern Recognition (**CVPR**) 2025

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/jiwoohong93/ita-mdt_code) [![Demo Page](https://img.shields.io/badge/Demo-Page-blue?logo=google-chrome&style=flat-square)](https://jiwoohong93.github.io/ita-mdt/)

</div>
</div>

## 2024

<div class='paper-box'><div class='paper-box-image'><div class="badge">Neurips 2024</div><img src='images/neurips2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C18**] [**TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation**](https://arxiv.org/abs/2410.24037)

<span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Younghwan Lee, and Chang D. Yoo

Neural Information Processing Systems (**NeurIPS**) 2024

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/dbstjswo505/TPC)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2024</div><img src='images/eccv2024_1.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C17**] [**Dilutional Noise Initialization for Dilution Video Editing**](https://arxiv.org/abs/2409.13037v1)

<span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Ji Woo Hong, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2024

(In process of U.S./J.P. patent registeration)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2024</div><img src='images/eccv2024_2.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C16**] [**FlexiEdit: Frequency-Aware Latent Refinement for Enhanced Non-Rigid Editing**](https://arxiv.org/abs/2407.17850)

Gwanhyeong Koo, <span style="color:royalblue">**Sunjae Yoon** </span>, Ji Woo Hong, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2024

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/kookie12/FlexiEdit)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICML 2024</div><img src='images/icml2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C15**] [**FRAG: Frequency Adapting Group for Diffusion Video Editing**](https://arxiv.org/pdf/2406.06044)

<span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Geonwoo Kim, and Chang D. Yoo

International Conference on Machine Learning (**ICML**), 2024

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/dbstjswo505/FRAG) [![Demo Page](https://img.shields.io/badge/Demo-Page-blue?logo=google-chrome&style=flat-square)](https://dbstjswo505.github.io/FRAG-page)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICPRAI 2024</div><img src='images/icprai_2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C14**] **Character Identifying Video Language Alignment Network for Weakly-Supervised Video-Subtitle Moment Retrieval**

Donghoon Lee ‚àó, Jun Yeop Shim ‚àó, <span style="color:royalblue">**Sunjae Yoon** </span>, and Chang D Yoo

International Conference on Pattern Recognition and Artificial Intelligence (**ICPRAI**), 2024, <span style="color:#8B0000">**Oral**</span>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Journal of the IEIE</div><img src='images/ieie_journal_2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J6**] [**Spatial Adaptive Kernel Network for Enhanced Oriented Ship Detection in Synthetic Aperture Radar Imagery**](https://www.dbpia.co.kr/pdf/pdfView.do?nodeId=NODE11947319&googleIPSandBox=false&mark=0&minRead=15&ipRange=false&b2cLoginYN=false&icstClss=010000&isPDFSizeAllowed=true&accessgl=Y&language=ko_KR&hasTopBanner=true)

Gwanhyeong Koo, <span style="color:royalblue">**Sunjae Yoon** </span>, Donghoon Lee, Soo Hwan Eom, JongSik Ahn, Tae-Young Lee, Chang D. Yoo.

Journal of The Institute of Electronics and Information Engineers, 2024
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">IEEE Access 2024</div><img src='images/access2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J5**] [**Causal Localization Network for Radar Human Localization with micro-Doppler signature**](https://ieeexplore.ieee.org/document/10387441)

<span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Jun Yeop Shim, Soohwan Eom, Ji Woo Hong, Chang D. Yoo

IEEE Access, 2024

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/dbstjswo505/CLNet)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2024</div><img src='images/icassp2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C13**] [**WAVELET-GUIDED ACCELERATION OF TEXT INVERSION IN DIFFUSION-BASED IMAGE EDITING**](https://arxiv.org/abs/2401.09794)

Gwanhyeong Koo, <span style="color:royalblue">**Sunjae Yoon** </span>, Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2024
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">AAAI 2024</div><img src='images/aaai2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C12**] [**SimPSI: A Simple Strategy to Preserve Spectral Information in Time Series Data Augmentation**](https://arxiv.org/pdf/2312.05790.pdf)

Hyun Ryu, <span style="color:royalblue">**Sunjae Yoon** </span>, Hee Suk Yoon, Eunseop Yoon, and Chang D. Yoo

AAAI Association for the Advancement of Artificial Intelligence (**AAAI**) 2024

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/Hyun-Ryu/simpsi)
</div>
</div>

## 2023

<div class='paper-box'><div class='paper-box-image'><div class="badge">EMNLP 2023</div><img src='images/hear.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C11**] [**HEAR: Hearing Enhanced Audio Response for Viode-grounded Dialogue**](https://aclanthology.org/2023.findings-emnlp.797.pdf)

<span style="color:royalblue">**Sunjae Yoon** </span>, Dahyun Kim, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, and Chang D. Yoo

Empirical Methods in Natural Language Processing (**EMNLP**) 2023 (long paper, findings)

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/dbstjswo505/HEAR) <span style="color:#8B0000">30th Samsung HumanTech Paper Award</span>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICCV 2023</div><img src='images/iccv2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C10**] [**SCANet: Scene Complexity Aware Network for Weakly-supervised Video Moment Retrieval**](https://openaccess.thecvf.com/content/ICCV2023/papers/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.pdf)

<span style="color:royalblue">**Sunjae Yoon** </span>, Gwanhyeong Koo, Dahyun Kim, and Chang D. Yoo

International Conference on Computer Vision (**ICCV**) 2023

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/dbstjswo505/SCANet)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2023</div><img src='images/icassp2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C9**] [**Counterfactual Two-stage Debiasing Network for Video Corpus Moment Retrieval**](https://ieeexplore.ieee.org/document/10095182)

<span style="color:royalblue">**Sunjae Yoon** </span>, Ji Woo Hong, SooHwan Eom, Hee Suk Yoon, Eunseop Yoon, Daehyeok Kim, Junyeong Kim, Chanwoo Kim, and Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2023, <span style="color:#8B0000">**Oral**</span>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2023</div><img src='images/access2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J4**] [**Joint Path Alignment Framework for 3D Human Pose and Shape Estimation from Video**](https://ieeexplore.ieee.org/document/10109716)

Ji Woo Hong, <span style="color:royalblue">**Sunjae Yoon** </span>, Junyeong Kim, and Chang D. Yoo  

IEEE Access, 2023

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Sensors 2022</div><img src='images/sensors2022_2.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J3**] [**CE-BART: Cause-and-Effect BART for Visual Comonsense Generation**](https://www.mdpi.com/1424-8220/22/23/9399)

Junyeong Kim, Ji Woo Hong, <span style="color:royalblue">**Sunjae Yoon** </span>, and Chang D. Yoo  

MDPI Sensors, 2022

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICLR 2023</div><img src='images/iclr2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C8**] [**ESD: EXPECTED SQUARED DIFFERENCE AS A TUNING-FREE TRAINABLE CALIBRATION MEASURE**](https://arxiv.org/pdf/2303.02472.pdf)

Hee Suk Yoon, Joshua Tian Jin Tee , Eunseop Yoon, <span style="color:royalblue">**Sunjae Yoon** </span>, Gwangsu Kim, Yingzhen Li, and Chang D. Yoo 

International Conference on Learning Representation (**ICLR**), 2023

</div>
</div>

## 2022

<div class='paper-box'><div class='paper-box-image'><div class="badge">EMNLP 2022</div><img src='images/emnlp2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C7**] [**Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue**](https://browse.arxiv.org/pdf/2212.05765.pdf)

<span style="color:royalblue">**Sunjae Yoon** </span>, Eunseop Yoon, Hee Suk Yoon, Junyeong Kim, and Chang D. Yoo

Empirical Methods in Natural Language Processing (**EMNLP**), 2022. (long paper)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">EMNLP 2022</div><img src='images/emnlp2022_findings.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C6**] [**SMSMix: Sense-Maintained Sentence Mixup for Word Sense Disambiguation**](https://arxiv.org/pdf/2212.07072.pdf)

Hee Suk Yoon , Eunseop Yoon , John Harvill, <span style="color:royalblue">**Sunjae Yoon** </span>, Mark Hasegawa-Johnson, and Chang D. Yoo

Empirical Methods in Natural Language Processing (**EMNLP**), 2022. (short paper, findings)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2022</div><img src='images/eccv2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C5**] [**Selective Query-guided Debiasing for Video Corpus Moment Retrieval**](https://arxiv.org/pdf/2210.08714.pdf) 

<span style="color:royalblue">**Sunjae Yoon** </span>, Ji Woo Hong, Eunseop Yoon, Dahyun Kim , Junyeong Kim, Hee Suk Yoon, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2022

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/dbstjswo505/SQuiDNet)  (Related Patent: U.S. 1,232,384)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Access 2022</div><img src='images/access2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J2**] [**Cascaded MPN: Cascaded Moment Proposal Network for Video Corpus Moment Retrieval**](https://ieeexplore.ieee.org/document/9795270) 

<span style="color:royalblue">**Sunjae Yoon** </span>, Dahyun Kim, Junyeong Kim, and Chang D. Yoo

IEEE Access 2022

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2022</div><img src='images/icassp2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C4**] [**SEMANTIC ASSOCIATION NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL**](https://ieeexplore.ieee.org/document/9747523) 

Dahyun Kim *, <span style="color:royalblue">**Sunjae Yoon** </span> *, Ji Woo Hong, and Chang D. Yoo

The International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2022. <span style="color:#8B0000">**Oral**</span>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Sensors 2022</div><img src='images/sensors2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J1**] [**Dual-Scale Doppler Attention for Human Identification**](https://www.mdpi.com/1424-8220/22/17/6363) 

<span style="color:royalblue">**Sunjae Yoon** </span>, Dahyun Kim, Ji Woo Hong, and Chang D. Yoo

MDPI Sensors, 2022

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/dbstjswo505/DSDA)

</div>
</div>

## 2021

<div class='paper-box'><div class='paper-box-image'><div class="badge">AAAI 2021</div><img src='images/aaai2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C3**] [**Structured Co-reference Graph Attention for Video-grounded Dialogue**](https://arxiv.org/pdf/2103.13361.pdf) 

Junyeong Kim, <span style="color:royalblue">**Sunjae Yoon** </span>, Dahyun Kim, and Chang D. Yoo

AAAI Association for the Advancement of Artificial Intelligence (**AAAI**), 2021

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICIP 2021</div><img src='images/icip2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C2**] [**WEAKLY-SUPERVISED MOMENT RETRIEVAL NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL**](https://ieeexplore.ieee.org/document/9506218) 

<span style="color:royalblue">**Sunjae Yoon** </span> *, Dahyun Kim *, Ji Woo Hong, Junyeong Kim, Kookhoi Kim and Chang D. Yoo

International Conference on Image Processing (**ICIP**), 2021

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/dbstjswo505/WMRN)

</div>
</div>

## 2020

<div class='paper-box'><div class='paper-box-image'><div class="badge">ECCV 2020</div><img src='images/eccv2020.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C1**] [**VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval**](https://arxiv.org/pdf/2008.10238.pdf)

Minuk Ma *, <span style="color:royalblue">**Sunjae Yoon** </span> *, Junyeong Kim, Youngjuoon Lee, Sunghun Kang, and Chang D. Yoo

European Conference on Computer Vision (**ECCV**) 2020

</div>
</div>

# Academic Activities

# üí¨ Invited Talks
- *2023.05*, CAU-AI Core Technology Seminar: Empirical Methods and Recent Topics for Video Moment Retrieval, (2023-05-19) 

# üèÜ Awards
- Outstanding Ph.D. Dissertation Award, School of Electrical Engineering, KAIST, (golden medal) (2025.03)

- Winner of Datathon Award, 2nd Seoul National University Bundang Hospital (SNUBH) Datathon Award, 1st Prize ($2,000) (2024.10)

- 30th Samsung HumanTech Paper Award, encouragement prize ($1,500) (2024.02)

- Winner of Best Paper Award, Winter Conference of Korean Artificial Intelligence Association (KAIA), ($1,500), (2023.11)

- Certificate of Commendation for Cum Laude Graduation, DGIST (2019.02)

- Certificate of Commendation from Dalseong-gun Office, Daegu (2019.02) 

- Award Bronze Prize for International University Creative Car Competition (Autonomous driving) by Korea Transportation Safety Authority, (2018.05)

- Award Excellence Prize in Autonomous Vehicle Creation Technology by Korea Auto Vehicle Safety Association, (2018.05)

# üìë Reviewer

**Confernce**

- Neural Information Processing Systems (**Neurips**): 2023 ~ 

- IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**) : 2022 ~

- European Conference on Computer Vision (**ECCV**): 2022 ~

- IEEE International Conference on Computer Vision (**ICCV**) : 2023 ~

- The Association for the Advancement of Artificial Intelligence (**AAAI**) : 2025 ~

- Association for Computational Linguistics (**ACL**): 2023 ~

- Empirical Methods on Natural Language Processing (**EMNLP**): 2022 ~

- International Conference on Learning Representations (**ICLR**): 2024 ~

- International Conference on Machine Learning (**ICML**): 2024 ~

- International Conference on Acoustics, Speech, and Signal Processing (**ICASSP**): 2023 ~ 

- IEEE/CVF Winter Conference on Applications of Computer Vision (**WACV**): 2023 ~

- International Conference on Artificial Intelligence and Statistics (**AISTATS**): 2025 ~

**Journal**
- IEEE Transactions on Big Data

- IEEE Transactions on Circuits and Systems for Video Technology

- International Journal of Human-Computer Interaction

- ACM Transactions on Multimedia, Computing, Communications, and Applications

- Expert Systems With Applications

# üìè Teaching Assistant

- Seongnam-KAIST Next Generation ICT Research Center EE Co-op+ Joint Research Program, 2024 Fall 

- Digital Speech Processing, 2024 Fall

- Signals and Systems, 2023 Spring, 2022 Fall, 2022 Spring, 2021 Spring

- Statistical Learning Theory, 2021 Fall


# üéè Patent

- METHOD AND DEVICE FOR VIDEO MOMENT RETRIEVAL BASED ON SELECTIVE DEBIASING No. US 1,232,384 (2025-06-03)

- METHOD AND DEVICE FOR VIDEO MOMENT RETRIEVAL BASED ON SELECTIVE DEBIASING No. KR 10-2022-0154621 (2022-11-17)

- WEAKLY-SUPERVISED MOMENT RETRIEVAL NETWORK FOR VIDEO CORPUS MOMENT RETRIEVAL No. KR 10-2021-0172582 (2021-12-06)

- Artificial Intelligence-based Radar Target Detection System No. KR 10-2557458 (2023-07-14)