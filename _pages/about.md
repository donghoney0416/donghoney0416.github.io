---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# üòÉ About me
Hello! I am Dongheon Lee, a research scientist intern at <strong>Meta Reality Labs</strong> <img src="images/meta_logo.png" alt="Meta" width="20"/> and also a postdoctoral researcher at <strong>KAIST</strong> <img src="images/kaist_logo.png" alt="kaist" width="40"/>. My research mainly focuses on <strong>multichannel sound source separation (speech enhancement, separation, and audio source separation)</strong>, including real-time, on-device models and array-agnostic processing. I am interested in AR/VR, and speech recognition. I obtained Ph.D. (2025) and B.S. (2020) at KAIST, advised by Professor [Jung-Woo Choi](https://www.sound.kaist.ac.kr/).

<u>Alert! I am looking for work starting in June 2026. If you would like to work with me, please feel free to contact me!</u>

For more information, please refer to my [CV](https://drive.google.com/file/d/1mfpebp1ZnteknwVx2V6Q3CFhz9y9fDVD/view?usp=sharing).

# üìå Research Interests
- Audio Signal Processing
- Speech Signal Processing
- Microphone Array Processing
- Generative AI (Speech/Audio)

# üî• News
- *2025.07*: &nbsp;üéâ <strong>1st rank</strong> in DCASE 2025 task 4: Spatial Semantic Segmentation of Sound Scenes
- *2025.06*: &nbsp;üéâ Join in <strong>Meta Reality Labs</strong> as research scientist intern
- *2025.03*: &nbsp;üéâ One paper accepted to Forum Acusticum <strong>Euronoise</strong>, 2025
- *2025.02*: &nbsp;üéâ End journey for <strong>Ph.D.</strong>, School of Electrical Engineering, KAIST

# üè´ Education

- Mar.2020 - Feb.2025: __Ph.D.__ Electrical Engineering (KAIST)

&emsp;&emsp;&emsp;Dissertation: "Unified Auditory Scene Analysis and Separation using Dense Frequency-Time Attentive Network"

&emsp;&emsp;&emsp;Advisor: Prof. [Jung-Woo Choi](https://www.sound.kaist.ac.kr/)

- Mar.2016 - Feb.2020: __B.S.__ Electrical Engineering (KAIST)

- Mar.2014 - Feb.2016: Changwon Science Highschool

&emsp;&emsp;&emsp;Early Graduation

# üìé Selected Publications 
[**6**] <span style="color:royalblue">**Dongheon Lee**</span>, Jung-Woo Choi, "DeFT-Mamba: Multichannel universal sound separation and polyphonic audio classification," International Conference on Audio, Speech, Signal Processing (**ICASSP**) 2025 (oral)

[**5**] <span style="color:royalblue">**Dongheon Lee**</span>, Jung-Woo Choi, "DeFTAN-II: Efficient multichannel speech enhancement with subgroup processing," IEEE/ACM Transactions on Audio, Speech, and Language Processing (**IEEE/ACM TASLP**) 2024

[**4**] <span style="color:royalblue">**Dongheon Lee**</span>, Jung-Woo Choi, "DeFTAN-AA: Array geometry-agnostic multichannel speech enhancement," International Speech Communication Association (**Interspeech**) 2024 (oral)

[**3**] <span style="color:royalblue">**Dongheon Lee**</span>, Dayun Choi, Jung-Woo Choi, "DeFT-AN RT: Real-time multichannel speech enhancement using Dense Frequency Time Attentive Network and non-overlapping synthesis window,," International Speech Communication Association (**Interspeech**) 2023

[**2**] <span style="color:royalblue">**Dongheon Lee**</span>, Jung-Woo Choi, "DeFT-AN: Dense Frequency-Time Attentive Network for multichannel speech enhancement," IEEE Signal Processing Letters (**IEEE SPL**) 2023

[**1**] <span style="color:royalblue">**Dongheon Lee**</span>, Byeongho Jo, Jung-Woo Choi, "Direction-of-arrival estimation with blind surface impedance compensation for spherical microphone array", Journal of Acoustical Society of America Express Letters (**JASA EL**) 2021

# üìù Publications (14 publications, 13 first-author)

## 2025
<div class='paper-box'><div class='paper-box-image'><div class="badge">DCASE 2025</div><img src='images/dcase2025.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C09**] [**Self-guided target sound extraction and classification through universal sound separation model and multiple clues**](https://dcase.community/documents/challenge2025/technical_reports/DCASE2025_Kwon_68_t4.pdf)

Younghoo Kwon\*, <span style="color:royalblue">**Dongheon Lee**</span>\*, Dohwan Kim, and Jung-Woo Choi (\*: Equal Contribution)

DCASE Technical Report <span style="color:#8B0000">**1st rank, Winner**</span> (**DCASE**) 2025

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">NeurIPS 2025</div><img src='images/neurips2025.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C08**] **DeepASA: An object-oriented one-for-all network for auditory scene analysis**

<span style="color:royalblue">**Dongheon Lee**</span>, Younghoo Kwon, and Jung-Woo Choi

Advances in Neural Information Processing Systems (**NeurIPS**) 2025, (submitted)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">EuroNoise 2025</div><img src='images/euronoise2025.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C07**] **Universal auditory scene analysis model for source separation, event localization, and detection**

<span style="color:royalblue">**Dongheon Lee**</span>, Jung-Woo Choi

Forum Acusticum Euronoise (**EuroNoise**) 2025

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ICASSP 2025</div><img src='images/icassp2025.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C06**] [**DeFT-Mamba: Multichannel universal sound separation and polyphonic audio classification**](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890324&casa_token=LRRbfPg3qQYAAAAA:sZ7Fj4-hS_uGuLnohen5m8nbDjhAFeo7uG8p074ojNe8jcfoURanlTcT3yVmOa-HYsTHhqeChzQ)

<span style="color:royalblue">**Dongheon Lee**</span>, Jung-Woo Choi

International Conference on Audio, Speech, Signal Processing (**ICASSP**) 2025 (oral)

[![Demo Page](https://img.shields.io/badge/Demo-Page-blue?logo=google-chrome&style=flat-square)](https://donghoney0416.github.io/DeFTMamba/)

</div>
</div>

## 2024

<div class='paper-box'><div class='paper-box-image'><div class="badge">IEEE/ACM TASLP 2024</div><img src='images/taslp2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J05, C05**] [**DeFTAN-II: Efficient multichannel speech enhancement with subgroup processing**](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10738447)

<span style="color:royalblue">**Dongheon Lee**</span>, Jung-Woo Choi

IEEE/ACM Transactions on Audio, Speech, and Language Processing (**IEEE/ACM TASLP**) 2024

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/donghoney0416/DeFTAN-II/tree/main) 
[![Demo Page](https://img.shields.io/badge/Demo-Page-blue?logo=google-chrome&style=flat-square)](https://donghoney0416.github.io/demos-DeFTAN-II/demo-page.html)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">Interspeech 2024</div><img src='images/interspeech2024.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C04**] [**DeFTAN-AA: Array geometry-agnostic multichannel speech enhancement**](https://www.isca-archive.org/interspeech_2024/lee24g_interspeech.pdf)

<span style="color:royalblue">**Dongheon Lee**</span>, Jung-Woo Choi

International Speech Communication Association (**Interspeech**) 2024 (oral)

[![Demo Page](https://img.shields.io/badge/Demo-Page-blue?logo=google-chrome&style=flat-square)](https://donghoney0416.github.io/DeFTAN-AA/)

</div>
</div>

## 2023

<div class='paper-box'><div class='paper-box-image'><div class="badge">Interspeech 2023</div><img src='images/interspeech2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C03**] [**DeFT-AN RT: Real-time multichannel speech enhancement using Dense Frequency Time Attentive Network and non-overlapping synthesis window**](https://www.isca-archive.org/interspeech_2023/lee23j_interspeech.pdf)

<span style="color:royalblue">**Dongheon Lee**</span>, Dayun Choi, and Jung-Woo Choi

International Speech Communication Association (**Interspeech**) 2023

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/donghoney0416/DeFT-AN-RT)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">IEEE SPL 2023</div><img src='images/spl2023.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J04, C02**] [**DeFT-AN: Dense Frequency-Time Attentive Network for multichannel speech enhancement**](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10042963&casa_token=ERaDPBaWXSQAAAAA:pU65_JHMliKhGhb3nBjPygHDgojc8GFN7hZyFZKw-d5I9ZQ0R7LxkvGpjuaH_pO3FmpKf0qqTOY)

<span style="color:royalblue">**Dongheon Lee**</span>, and Jung-Woo Choi

IEEE Signal Processing Letters (**IEEE SPL**) 2023

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/donghoney0416/DeFT-AN)

</div>
</div>

## 2022

<div class='paper-box'><div class='paper-box-image'><div class="badge">Inter-Noise 2022</div><img src='images/internoise2022.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**C01**] [**Inter-channel Conv-TasNet for source-agnostic multichannel audio enhancement**](https://www.ioa.org.uk/system/files/proceedings/d_lee_jw_choi_inter-channel_conv-tasnet_for_source-agnostic_multichannel_audio_enhancement.pdf)

<span style="color:royalblue">**Dongheon Lee**</span>, Jung-Woo Choi

51st International Congress Exposition on Noise Controal Engineering (**Inter-Noise**), 2022. (oral)

</div>
</div>

## 2021

<div class='paper-box'><div class='paper-box-image'><div class="badge">Nanoscale 2021</div><img src='images/nanoscale2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J03**] [**Wafer-scale, highly uniform, and well-arrayed suspended nanostructures for enhancing the performance of electronic devices**](https://pubs.rsc.org/en/content/articlelanding/2022/nr/d1nr07375c/unauth) 

Zhi-Jun Zhao, Junseong Ahn, <span style="color:royalblue">**Dongheon Lee**</span>, et. al.

Nanoscale, 2021

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">ArXiv 2021</div><img src='images/arxiv2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J02**] [**Inter-channel Conv-TasNet for multichannel speech enhancement**](https://arxiv.org/pdf/2111.04312) 

<span style="color:royalblue">**Dongheon Lee**</span>, Seongrae Kim, and Jung-Woo Choi

ArXiv, 2021

[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-black?logo=github&style=flat-square)](https://github.com/donghoney0416/IC_Conv-TasNet)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div class="badge">JASA EL 2021</div><img src='images/jasa2021.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**J01**] [**Direction-of-arrival estimation with blind surface impedance compensation for spherical microphone array**](https://pubs.aip.org/asa/jel/article/1/7/074801/219823)

<span style="color:royalblue">**Dongheon Lee**</span>, Byeongho Jo, Jung-Woo Choi

Journal of Acoustical Society of America Express Letters (**JASA EL**) 2021

</div>
</div>

# Academic Activities

# üí¨ Invited Talks 
- *2024* Machine Learning and Big Data, Next-Generation ICT Research Center
- *2023* On-device multichannel speech enhancement system, AICube
- *2023* AI Specialized Training Program, KAIST-Hwaseong Hub

# üèÜ Awards
- 1st Rank (Winner) of DCASE 2025 Task 4: Spatial Semantic Segmentation of Sound Scenes (2025)
  
- Outstanding Teaching Assistant Award, EE488B: Audio Signal Processing (2024)

- Excellence Paper Award, Acoustical Society of Korea (2021)
  
- 1st Prize in Internship Project, SK Hynix (2019)

# üìë Reviewer

**Confernce**
- IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (**WASPAA**): 2025 ~

- International Conference on Audio, Speech, Signal Processing (**ICASSP**): 2025 ~

- Proceedings of International Speech Communication Association (**Interspeech**): 2025 ~

**Journal**
- IEEE/ACM Transactions on Audio, Speech, and Language Processing (**IEEE/ACM TASLP**)

- IEEE Signal Processing Letters (**IEEE SPL**)

# üìè Teaching Assistant

- Signals and Systems, Mar. 2021 -- Feb. 2024

- Audio Signal Processing, Feb. 2024 -- Jun. 2024

- Individual Research, Mar. 2021 -- Aug. 2024

# üéè Patent

- Method and device of suppressing outdoor noise by using a microphone array, KR 10-2022-0131773

- Method and apparatus for array geometry agnostic denoising and dereverberation based on deep learning, KR 10-2024-0063256

- Voice enhancement method and system in eXtended Reality space for multi-party voice conversation, KR 10-2023-0150037
